# LTXV LoRA Training Configuration

# Model configuration
model:
  model_source: "LTXV_2B_098_DISTILLED" # Options: "LTXV_13B_097_DEV", "LTXV_2B_0.9.6_DEV", "LTXV_2B_0.9.5", "LTXV_2B_0.9.1", "LTXV_2B_0.9.0", or a HF repo/local path
  training_mode: "full" # Options: "lora" or "full"
  load_checkpoint: null # Path to checkpoint file or directory to resume from. If directory, latest checkpoint will be used.

# Conditioning configuration
conditioning:
  mode: "none" # Options: "none", "reference_video"
  first_frame_conditioning_p: 1.0
  n_cond_latents: 4

# Optimization configuration
optimization:
  learning_rate: 1e-5
  steps: 30000
  batch_size: 2
  gradient_accumulation_steps: 32  # 2 gpus
  max_grad_norm: 1.0
  optimizer_type: "adamw" # Options: "adamw" or "adamw8bit"
  scheduler_type: "linear" # Options: "constant", "linear", "cosine", "cosine_with_restarts", "polynomial"
  scheduler_params: {}
  enable_gradient_checkpointing: false

# Acceleration optimization
acceleration:
  mixed_precision_mode: "bf16" # Options: "no", "fp16", "bf16"
  quantization: null # Options: null, "int8-quanto", "int4-quanto", "int2-quanto", "fp8-quanto", "fp8uz-quanto"
  load_text_encoder_in_8bit: true # Load text encoder in 8-bit precision to save memory
  compile_with_inductor: false
  compilation_mode: "reduce-overhead" # Options: "default", "reduce-overhead", "max-autotune"

# Data configuration
data:
  preprocessed_data_root: "/mnt/home/anthony/datasets/cs2/train_288x512"
  num_dataloader_workers: 8

# Validation configuration
validation:
  prompts:
    - "A video of a professional gamer playing Counter Strike 2."
    - "A video of a professional gamer playing Counter Strike 2."
    - "A video of a professional gamer playing Counter Strike 2."
    - "A video of a professional gamer playing Counter Strike 2."
  videos:
    - /mnt/home/anthony/datasets/cs2/validation/000b16_4569111908431607_25_25frames.mp4
    - /mnt/home/anthony/datasets/cs2/validation/000b5d_4576870262605658_9_25frames.mp4
    - /mnt/home/anthony/datasets/cs2/validation/004b62_4605849359270485_6_25frames.mp4
    - /mnt/home/anthony/datasets/cs2/validation/008b57_4596395269255883_5_25frames.mp4
  negative_prompt: "worst quality, inconsistent motion, blurry, jittery, distorted"
  video_dims: [512, 288, 73] # [width, height, frames]
  seed: 42
  inference_steps: 50
  interval: 500 # Set to null to disable validation
  videos_per_prompt: 1
  guidance_scale: 1.0

# Checkpoint configuration
checkpoints:
  interval: 1000 # Save a checkpoint every N steps, set to null to disable
  keep_last_n: 1 # Keep only the N most recent checkpoints, set to -1 to keep all

# Flow matching configuration
flow_matching:
  timestep_sampling_mode: "shifted_logit_normal" # Options: "uniform", "shifted_logit_normal"
  timestep_sampling_params: {}

# HuggingFace Hub configuration
hub:
  push_to_hub: false # Whether to push the model weights to the Hugging Face Hub
  hub_model_id: null # Hugging Face Hub repository ID (e.g., 'username/repo-name'). Must be provided if `push_to_hub` is set to True

# W&B configuration
wandb:
  enabled: true  # Set to true to enable W&B logging
  project: "ltxv-trainer"
  #entity: null  # Your W&B username or team
  tags: []
  log_validation_videos: true

# General configuration
seed: 42
output_dir: "outputs/2b_full_cs2_bs128_288x512"
